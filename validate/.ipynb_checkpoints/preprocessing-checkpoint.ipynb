{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, sent_tokenize as to_sentences\n",
    "import string\n",
    "import re\n",
    "from contractions import contractions_dict\n",
    "from article_summariser import getSummary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contractions_dict):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())), flags = re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    def expand_match(contraction):\n",
    "\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) if contractions_dict.get(match) else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        \n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    \n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article_body(body):\n",
    "    \n",
    "    if not isinstance(body, str):\n",
    "        \n",
    "        raise ValueError(\"Expected a string input. Received an object of class \" + type(body).__name__ + \" instead.\")\n",
    "        \n",
    "    # get summary of the article in seven sentences\n",
    "    body = getSummary(body)\n",
    "    \n",
    "    # article body to list of sentences\n",
    "    sentences = to_sentences(body)\n",
    "    \n",
    "    # mapping from punctuations to empty string\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    for idx in range(len(sentences)):\n",
    "        \n",
    "        # get sentence\n",
    "        sentence = sentences[idx]\n",
    "        \n",
    "        # replace characters with replacements\n",
    "        replacements = {\"\\n\": \"\", \"\\r\": \"\", \"-\": \" - \"}\n",
    "        for to_replace, replacement in replacements.items():\n",
    "            sentence = sentence.replace(to_replace, replacement)\n",
    "        \n",
    "        # remove extra spaces\n",
    "        sentence = re.sub(\" +\", \" \", sentence)\n",
    "        \n",
    "        # remove anything in brackets\n",
    "        sentence = re.sub(r\"\\([^()]*\\)\", \"\", sentence)\n",
    "        \n",
    "        # remove punctuation\n",
    "        sentence = \" \".join([word.translate(table) for word in word_tokenize(sentence)])\n",
    "        \n",
    "        # expand contractions\n",
    "        sentence = expand_contractions(sentence, contractions_dict)\n",
    "        \n",
    "        # encode to utf-8\n",
    "        sentence = sentence.encode(encoding = \"utf-8\", errors = \"ignore\").decode(\"utf-8\")\n",
    "        \n",
    "        # set sentence\n",
    "        sentences[idx] = sentence\n",
    "        \n",
    "    # join sentences comma separated\n",
    "    body = \", \".join(sentences)\n",
    "    \n",
    "    # return cleaned body    \n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(bodies, stances):\n",
    "    \n",
    "    flagged_ids = []\n",
    "    \n",
    "    for idx, row in bodies.iterrows():\n",
    "        \n",
    "        body_id, article_body = row[\"Body ID\"], row[\"articleBody\"]\n",
    "        \n",
    "        if len(to_sentences(article_body)) < 7:\n",
    "            flagged_ids.append(body_id)\n",
    "        else:\n",
    "            bodies[bodies[\"Body ID\"] == body_id] = (body_id, process_article_body(article_body))\n",
    "            \n",
    "    for body_id in flagged_ids:\n",
    "        \n",
    "        bodies = bodies[bodies[\"Body ID\"] != body_id]\n",
    "        stances = stances[stances[\"Body ID\"] != body_id]\n",
    "    \n",
    "    return bodies, stances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1683, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(49972, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(904, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25413, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1468, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(43543, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(756, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20779, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"./data/raw/train_bodies.csv\", header = 0)\n",
    "train_stances = pd.read_csv(\"./data/raw/train_stances.csv\", header = 0)\n",
    "test_bodies = pd.read_csv(\"./data/raw/test_bodies.csv\", header = 0)\n",
    "test_stances = pd.read_csv(\"./data/raw/test_stances.csv\", header = 0)\n",
    "\n",
    "print(\"Raw Data\")\n",
    "\n",
    "train_bodies.shape\n",
    "train_stances.shape\n",
    "test_bodies.shape\n",
    "test_stances.shape\n",
    "\n",
    "train_bodies_transformed, train_stances_transformed = transform(train_bodies, train_stances)\n",
    "test_bodies_transformed, test_stances_transformed = transform(test_bodies, test_stances)\n",
    "\n",
    "print(\"\\nTransformed Data\")\n",
    "\n",
    "train_bodies_transformed.shape\n",
    "train_stances_transformed.shape\n",
    "test_bodies_transformed.shape\n",
    "test_stances_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(54110, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(378, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10212, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_train_bodies, test_bodies_new = train_test_split(test_bodies_transformed, test_size = 0.5, shuffle = True)\n",
    "train_bodies_new = pd.concat([train_bodies_transformed, to_train_bodies], ignore_index = True)\n",
    "to_train_stances = test_stances_transformed[test_stances_transformed[\"Body ID\"].isin(to_train_bodies[\"Body ID\"].values)]\n",
    "train_stances_new = pd.concat([train_stances_transformed, to_train_stances], ignore_index = True)\n",
    "test_stances_new = test_stances_transformed[~test_stances_transformed[\"Body ID\"].isin(to_train_bodies[\"Body ID\"].values)]\n",
    "\n",
    "train_bodies_new.shape\n",
    "train_stances_new.shape\n",
    "test_bodies_new.shape\n",
    "test_stances_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies_new.to_csv(\"./data/processed/train_bodies.csv\", index = False)\n",
    "train_stances_new.to_csv(\"./data/processed/train_stances.csv\", index = False)\n",
    "test_bodies_new.to_csv(\"./data/processed/test_bodies.csv\", index = False)\n",
    "test_stances_new.to_csv(\"./data/processed/test_stances.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitfd92962200d74e8ba4e1089743d69310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
