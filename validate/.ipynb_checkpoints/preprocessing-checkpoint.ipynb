{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, sent_tokenize as to_sentences\n",
    "import string\n",
    "import re\n",
    "from contractions import contractions_dict\n",
    "from article_summariser import getSummary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contractions_dict):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())), flags = re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    def expand_match(contraction):\n",
    "\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) if contractions_dict.get(match) else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        \n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    \n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article_body(body):\n",
    "    \n",
    "    if not isinstance(body, str):\n",
    "        \n",
    "        raise ValueError(\"Expected a string input. Received an object of class \" + type(body).__name__ + \" instead.\")\n",
    "        \n",
    "    # get summary of the article in seven sentences\n",
    "    body_summary = getSummary(body)\n",
    "    \n",
    "    # article body to list of sentences\n",
    "    sentences = to_sentences(body_summary)\n",
    "    try:\n",
    "        assert len(sentences) == 7\n",
    "    except:\n",
    "        print(f\"Expected length of summary was 7. Found length {len(sentences)} instead. Length of article is {len(to_sentences(body))}.\\n\\nArticle Body -\\n\\n{body}\\n\\nSummary -\\n\\n{body_summary}\")\n",
    "        raise AssertionError\n",
    "    \n",
    "    # mapping from punctuations to empty string\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    \n",
    "    for idx in range(len(sentences)):\n",
    "        \n",
    "        # get sentence\n",
    "        sentence = sentences[idx]\n",
    "        \n",
    "        # replace characters with replacements\n",
    "        replacements = {\"\\n\": \"\", \"\\r\": \"\", \"-\": \" - \"}\n",
    "        for to_replace, replacement in replacements.items():\n",
    "            sentence = sentence.replace(to_replace, replacement)\n",
    "        \n",
    "        # remove extra spaces\n",
    "        sentence = re.sub(\" +\", \" \", sentence)\n",
    "        \n",
    "        # remove anything in brackets\n",
    "        sentence = re.sub(r\"\\([^()]*\\)\", \"\", sentence)\n",
    "        \n",
    "        # remove punctuation\n",
    "        sentence = \" \".join([word.translate(table) for word in word_tokenize(sentence)])\n",
    "        \n",
    "        # expand contractions\n",
    "        sentence = expand_contractions(sentence, contractions_dict)\n",
    "        \n",
    "        # encode to utf-8\n",
    "        sentence = sentence.encode(encoding = \"utf-8\", errors = \"ignore\").decode(\"utf-8\")\n",
    "        \n",
    "        # set sentence\n",
    "        sentences[idx] = sentence\n",
    "        \n",
    "    # join sentences comma separated\n",
    "    body = \", \".join(sentences)\n",
    "    \n",
    "    # return cleaned body    \n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(bodies, stances):\n",
    "    \n",
    "    flagged_ids = []\n",
    "    \n",
    "    for idx, row in bodies.iterrows():\n",
    "        \n",
    "        body_id, article_body = row[\"Body ID\"], row[\"articleBody\"]\n",
    "        \n",
    "        body_sentences = to_sentences(article_body)        \n",
    "        if len(body_sentences) < 7:\n",
    "            flagged_ids.append(body_id)\n",
    "        else:\n",
    "            try:\n",
    "                assert len(to_sentences(article_body)) >= 7\n",
    "            except:\n",
    "                print(f\"Expected length >= 7. Found {len(body_sentences)} instead.\\n{article_body}\")\n",
    "                raise AssertionError\n",
    "            bodies[bodies[\"Body ID\"] == body_id] = (body_id, process_article_body(article_body))\n",
    "            \n",
    "    for body_id in flagged_ids:\n",
    "        \n",
    "        bodies = bodies[bodies[\"Body ID\"] != body_id]\n",
    "        stances = stances[stances[\"Body ID\"] != body_id]\n",
    "    \n",
    "    return bodies, stances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1683, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(49972, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(904, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25413, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length of summary was 7. Found length 6 instead. Length of article is 15.\n",
      "\n",
      "Article Body -\n",
      "\n",
      "An article saying NASA confirmed six days of “total darkness” in December is fake and it’s merely an iteration of an old Internet hoax.\r\n",
      "\r\n",
      "Essentially every year, there’s bogus rumors saying that there will be three days of darkness in December, but they’ve obviously proven not to be true.\r\n",
      "\r\n",
      "They seem to reference the Three Days of Darkness mentioned by Catholic prophets.\r\n",
      "\r\n",
      "However, a “satirical” and entertainment website, Huzlers.com, posted an article about six days of darkness. It uses fake quotes from a NASA official.\r\n",
      "\r\n",
      "“WORLDWIDE – NASA has confirmed that the Earth will experience 6 days of almost complete darkness and will happen from the dates Tuesday the 16 – Monday the 22 in December. The world will remain, during these three days, without sunlight due to a solar storm, which will cause dust and space debris to become plentiful and thus, block 90% sunlight,” it reads in part.\r\n",
      "\r\n",
      "But Huzlers has a disclaimer that says it’s not real and shouldn’t ever be taken seriously.\r\n",
      "\r\n",
      "“Huzlers.com is a combination of real shocking news and satirical entertainment to keep its visitors in a state of disbelier,” the About Us section reads on the bottom of each web page.\r\n",
      "\r\n",
      "The bogus NASA article had tens of thousands of shares and “likes” on Saturday.\r\n",
      "\r\n",
      "According to Snopes.com, similar rumors have been going on for a while and have taken on different forms.\r\n",
      "\r\n",
      "“No, the universe is not about to realign in December 2014, nor will there be a three-day blackout at that time during which the Earth will shift into a new dimension. Neither NASA nor any other credible scientific entity has made such a pronouncement. Ever,” the site says. “This item originated back in 2012, when interest in the belief that the Mayan calendar would end on 21 December 2012 (thus foretelling the end of the world as we know it) was running high, and it has simply been updated and recirculated with the year 2014 replacing the original references to 2012.”\n",
      "\n",
      "Summary -\n",
      "\n",
      "The world will remain, during these three days, without sunlight due to a solar storm, which will cause dust and space debris to become plentiful and thus, block 90% sunlight,” it reads in part. “This item originated back in 2012, when interest in the belief that the Mayan calendar would end on 21 December 2012 (thus foretelling the end of the world as we know it) was running high, and it has simply been updated and recirculated with the year 2014 replacing the original references to 2012.” An article saying NASA confirmed six days of “total darkness” in December is fake and it’s merely an iteration of an old Internet hoax. Essentially every year, there’s bogus rumors saying that there will be three days of darkness in December, but they’ve obviously proven not to be true. However, a “satirical” and entertainment website, Huzlers.com, posted an article about six days of darkness. “Huzlers.com is a combination of real shocking news and satirical entertainment to keep its visitors in a state of disbelier,” the About Us section reads on the bottom of each web page. They seem to reference the Three Days of Darkness mentioned by Catholic prophets.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-19742dc51ab4>\u001b[0m in \u001b[0;36mprocess_article_body\u001b[1;34m(body)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-75a3a1d6473c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtest_stances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrain_bodies_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_stances_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_bodies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_stances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtest_bodies_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_stances_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_bodies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_stances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-efa8b4d64b55>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(bodies, stances)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected length >= 7. Found {len(body_sentences)} instead.\\n{article_body}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mbodies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbodies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Body ID\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbody_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbody_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_article_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbody_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflagged_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-19742dc51ab4>\u001b[0m in \u001b[0;36mprocess_article_body\u001b[1;34m(body)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected length of summary was 7. Found length {len(sentences)} instead. Length of article is {len(to_sentences(body))}.\\n\\nArticle Body -\\n\\n{body}\\n\\nSummary -\\n\\n{body_summary}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# mapping from punctuations to empty string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"./data/raw/train_bodies.csv\", header = 0)\n",
    "train_stances = pd.read_csv(\"./data/raw/train_stances.csv\", header = 0)\n",
    "test_bodies = pd.read_csv(\"./data/raw/test_bodies.csv\", header = 0)\n",
    "test_stances = pd.read_csv(\"./data/raw/test_stances.csv\", header = 0)\n",
    "\n",
    "print(\"Raw Data\")\n",
    "\n",
    "train_bodies.shape\n",
    "train_stances.shape\n",
    "test_bodies.shape\n",
    "test_stances.shape\n",
    "\n",
    "train_bodies_transformed, train_stances_transformed = transform(train_bodies, train_stances)\n",
    "test_bodies_transformed, test_stances_transformed = transform(test_bodies, test_stances)\n",
    "\n",
    "print(\"\\nTransformed Data\")\n",
    "\n",
    "train_bodies_transformed.shape\n",
    "train_stances_transformed.shape\n",
    "test_bodies_transformed.shape\n",
    "test_stances_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train_bodies, test_bodies_new = train_test_split(test_bodies_transformed, test_size = 0.5, shuffle = True)\n",
    "train_bodies_new = pd.concat([train_bodies_transformed, to_train_bodies], ignore_index = True)\n",
    "to_train_stances = test_stances_transformed[test_stances_transformed[\"Body ID\"].isin(to_train_bodies[\"Body ID\"].values)]\n",
    "train_stances_new = pd.concat([train_stances_transformed, to_train_stances], ignore_index = True)\n",
    "test_stances_new = test_stances_transformed[~test_stances_transformed[\"Body ID\"].isin(to_train_bodies[\"Body ID\"].values)]\n",
    "\n",
    "train_bodies_new.shape\n",
    "train_stances_new.shape\n",
    "test_bodies_new.shape\n",
    "test_stances_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies_new.to_csv(\"./data/processed/train_bodies.csv\", index = False)\n",
    "train_stances_new.to_csv(\"./data/processed/train_stances.csv\", index = False)\n",
    "test_bodies_new.to_csv(\"./data/processed/test_bodies.csv\", index = False)\n",
    "test_stances_new.to_csv(\"./data/processed/test_stances.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitfd92962200d74e8ba4e1089743d69310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
