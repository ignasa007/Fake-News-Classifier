{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, sent_tokenize as to_sentences\n",
    "import string\n",
    "import re\n",
    "from contractions import contractions_dict\n",
    "from article_summariser import getSummary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contractions_dict):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())), flags = re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    def expand_match(contraction):\n",
    "\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) if contractions_dict.get(match) else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        \n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    \n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article_body(body):\n",
    "    \n",
    "    if not isinstance(body, str):\n",
    "        raise ValueError(\"Expected a string input. Received an object of class \" + type(body).__name__ + \" instead.\")\n",
    "        \n",
    "    # preprocessing\n",
    "    replacements = {\"\\n\": \" \", \"\\r\": \" \", \"“\": '\"', \"”\": '\"', \"‘\": \"'\", \"’\": \"'\"}\n",
    "    for to_replace, replacement in replacements.items():\n",
    "        body = body.replace(to_replace, replacement)\n",
    "    body = re.sub(\" +\", \" \", body)\n",
    "    body = re.sub(r\"\\([^()]*\\)\", \"\", body)\n",
    "    sentences = to_sentences(body)\n",
    "    \n",
    "    # mapping from punctuations to empty string\n",
    "    table = str.maketrans({to_replace: (\" \" if to_replace == \"-\" else \"\") for to_replace in string.punctuation})\n",
    "    \n",
    "    for idx in range(len(sentences)):\n",
    "        \n",
    "        # get sentence\n",
    "        sentence = sentences[idx]\n",
    "        \n",
    "        # expand contractions\n",
    "        sentence = expand_contractions(sentence, contractions_dict)\n",
    "        \n",
    "        # remove punctuation\n",
    "        sentence = \" \".join([word.translate(table) for word in word_tokenize(sentence)])\n",
    "        \n",
    "        # remove leading and trailing spaces\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        # remove extra spaces\n",
    "        sentence = re.sub(\" +\", \" \", sentence)\n",
    "        \n",
    "        # encode to utf-8\n",
    "        sentence = sentence.encode(encoding = \"utf-8\", errors = \"ignore\").decode(\"utf-8\")\n",
    "        \n",
    "        # set sentence\n",
    "        sentences[idx] = sentence\n",
    "        \n",
    "    # join sentences comma separated\n",
    "    body = \". \".join(sentences)\n",
    "    \n",
    "    # return cleaned body    \n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(bodies, stances):\n",
    "    \n",
    "    flagged_ids = []\n",
    "    \n",
    "    for _, row in tqdm(bodies.iterrows()):\n",
    "        \n",
    "        body_id, article_body = row[\"Body ID\"], row[\"articleBody\"]\n",
    "        processed_article_body = process_article_body(article_body)\n",
    "        bodies[bodies[\"Body ID\"] == body_id] = (body_id, processed_article_body)\n",
    "    \n",
    "    assert not len(set(stances[\"Body ID\"]).difference(set(bodies[\"Body ID\"])))\n",
    "    \n",
    "    return bodies, stances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1683, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(49972, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(904, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25413, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1683it [00:31, 53.00it/s]\n",
      "904it [00:16, 55.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1683, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(49972, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(904, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25413, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies = pd.read_csv(\"./data/raw/train_bodies.csv\", header = 0)\n",
    "train_stances = pd.read_csv(\"./data/raw/train_stances.csv\", header = 0)\n",
    "test_bodies = pd.read_csv(\"./data/raw/test_bodies.csv\", header = 0)\n",
    "test_stances = pd.read_csv(\"./data/raw/test_stances.csv\", header = 0)\n",
    "\n",
    "print(\"Raw Data\")\n",
    "\n",
    "train_bodies.shape\n",
    "train_stances.shape\n",
    "test_bodies.shape\n",
    "test_stances.shape\n",
    "\n",
    "train_bodies_transformed, train_stances_transformed = transform(train_bodies.copy(), train_stances.copy())\n",
    "test_bodies_transformed, test_stances_transformed = transform(test_bodies.copy(), test_stances.copy())\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2135, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(62845, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(452, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(12540, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_train_bodies, test_bodies_new = train_test_split(test_bodies_transformed, test_size = 0.5, shuffle = True)\n",
    "train_bodies_new = pd.concat([train_bodies_transformed, to_train_bodies], ignore_index = True)\n",
    "to_train_stances = test_stances_transformed[test_stances_transformed[\"Body ID\"].isin(to_train_bodies[\"Body ID\"].values)]\n",
    "train_stances_new = pd.concat([train_stances_transformed, to_train_stances], ignore_index = True)\n",
    "test_stances_new = test_stances_transformed[~test_stances_transformed[\"Body ID\"].isin(to_train_bodies[\"Body ID\"].values)]\n",
    "\n",
    "train_bodies_new.shape\n",
    "train_stances_new.shape\n",
    "test_bodies_new.shape\n",
    "test_stances_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies_new.to_csv(\"./data/processed/train_bodies.csv\", index = False)\n",
    "train_stances_new.to_csv(\"./data/processed/train_stances.csv\", index = False)\n",
    "test_bodies_new.to_csv(\"./data/processed/test_bodies.csv\", index = False)\n",
    "test_stances_new.to_csv(\"./data/processed/test_stances.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitfd92962200d74e8ba4e1089743d69310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
